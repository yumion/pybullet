{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pybullet_envs/bullet\n"
     ]
    }
   ],
   "source": [
    "from pybullet_envs.bullet.kukaCamGymEnv import KukaCamGymEnv\n",
    "env = KukaCamGymEnv(renders=True, isDiscrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from baselines import deepq\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callback(lcl, glb):\n",
    "    # stop training if reward exceeds 199\n",
    "    total = sum(lcl['episode_rewards'][-101:-1]) / 100\n",
    "    totalt = lcl['t']\n",
    "    #print(\"totalt\")\n",
    "    #print(totalt)\n",
    "    is_solved = totalt > 2000 and total >= 10\n",
    "    return is_solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = deepq.models.cnn_to_mlp(\n",
    "    convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)],\n",
    "    hiddens=[256],\n",
    "    dueling=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepstation/.pyenv/versions/anaconda3-4.3.0/envs/pybullet/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/deepstation/.pyenv/versions/anaconda3-4.3.0/envs/pybullet/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 2         |\n",
      "| mean 100 episode reward | -4.32e+03 |\n",
      "| steps                   | 1000      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 3         |\n",
      "| mean 100 episode reward | -3.39e+03 |\n",
      "| steps                   | 1552      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 4         |\n",
      "| mean 100 episode reward | -3.48e+03 |\n",
      "| steps                   | 2301      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 5         |\n",
      "| mean 100 episode reward | -3.84e+03 |\n",
      "| steps                   | 3302      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 6         |\n",
      "| mean 100 episode reward | -3.55e+03 |\n",
      "| steps                   | 3764      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 7         |\n",
      "| mean 100 episode reward | -3.47e+03 |\n",
      "| steps                   | 4455      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 8         |\n",
      "| mean 100 episode reward | -3.31e+03 |\n",
      "| steps                   | 4991      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 9         |\n",
      "| mean 100 episode reward | -3.23e+03 |\n",
      "| steps                   | 5561      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 10        |\n",
      "| mean 100 episode reward | -3.31e+03 |\n",
      "| steps                   | 6415      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 11        |\n",
      "| mean 100 episode reward | -3.18e+03 |\n",
      "| steps                   | 6910      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 12        |\n",
      "| mean 100 episode reward | -3.09e+03 |\n",
      "| steps                   | 7369      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 13        |\n",
      "| mean 100 episode reward | -3.02e+03 |\n",
      "| steps                   | 7827      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 14        |\n",
      "| mean 100 episode reward | -2.99e+03 |\n",
      "| steps                   | 8427      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 2         |\n",
      "| episodes                | 15        |\n",
      "| mean 100 episode reward | -3.18e+03 |\n",
      "| steps                   | 9428      |\n",
      "---------------------------------------\n",
      "Saving model to kuka_cam_model.pkl\n"
     ]
    }
   ],
   "source": [
    "act = deepq.learn(\n",
    "    env,\n",
    "    q_func=model,\n",
    "    lr=1e-3,\n",
    "    max_timesteps=10000000,\n",
    "    buffer_size=50000,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.02,\n",
    "    print_freq=1,\n",
    "    callback=callback\n",
    ")\n",
    "print(\"Saving model to kuka_cam_model.pkl\")\n",
    "act.save(\"kuka_cam_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "Only one local in-process GUI/GUI_SERVER connection allowed. Use DIRECT connection mode or start a separate GUI physics server (ExampleBrowser, App_SharedMemoryPhysics_GUI, App_SharedMemoryPhysics_VR) and connect over SHARED_MEMORY, UDP or TCP instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d46c3af5ed34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#trainしたデータを使う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpybullet_envs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbullet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkukaCamGymEnv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKukaCamGymEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKukaCamGymEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misDiscrete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pybullet_envs/bullet/kukaCamGymEnv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, urdfRoot, actionRepeat, isEnableSelfCollision, renders, isDiscrete)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mcid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHARED_MEMORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m          \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGUI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetDebugVisualizerCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.52\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: Only one local in-process GUI/GUI_SERVER connection allowed. Use DIRECT connection mode or start a separate GUI physics server (ExampleBrowser, App_SharedMemoryPhysics_GUI, App_SharedMemoryPhysics_VR) and connect over SHARED_MEMORY, UDP or TCP instead."
     ]
    }
   ],
   "source": [
    "#trainしたデータを使う\n",
    "from pybullet_envs.bullet.kukaCamGymEnv import KukaCamGymEnv\n",
    "env = KukaCamGymEnv(renders=True, isDiscrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from baselines import deepq\n",
    "act = deepq.load(\"kuka_cam_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===episode: 0 ================================\n",
      "obs\n",
      "[[[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " ..., \n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [101 141 202 255]]]\n",
      "Episode reward -751.1184772909022\n",
      "===episode: 1 ================================\n",
      "obs\n",
      "[[[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]\n",
      "  [ 76 106 153 255]]\n",
      "\n",
      " ..., \n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]]\n",
      "\n",
      " [[162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  [162 186 224 255]\n",
      "  ..., \n",
      "  [100 141 202 255]\n",
      "  [100 141 202 255]\n",
      "  [101 141 202 255]]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-27f67cc199e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mepisode_rew\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Episode reward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_rew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pybullet_envs/bullet/kukaCamGymEnv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mrealAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep2\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrealAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pybullet_envs/bullet/kukaCamGymEnv.py\u001b[0m in \u001b[0;36mstep2\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m#print(self._envStepCounter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_termination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m#print(\"len=%r\" % len(self._observation))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl-box/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/pybullet_envs/bullet/kukaCamGymEnv.py\u001b[0m in \u001b[0;36m_termination\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_termination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m#print (self._kuka.endEffectorPos[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLinkState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kuka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkukaUid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kuka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkukaEndEffectorIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mactualEndEffectorPos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "episodes = 100\n",
    "for episode in range(episodes):\n",
    "    obs, done = env.reset(), False\n",
    "    print(\"===episode:\",episode,\"================================\")        \n",
    "    print(\"obs\")\n",
    "    print(obs)\n",
    "    episode_rew = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        obs, rew, done, _ = env.step(act(obs[None])[0])\n",
    "        episode_rew += rew\n",
    "    print(\"Episode reward\", episode_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
